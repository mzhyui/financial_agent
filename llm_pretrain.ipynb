{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6144293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-14 11:54:31 nemo_logging:405] /home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "      from .autonotebook import tqdm as notebook_tqdm\n",
      "    \n",
      "WARNING: transformer_engine not installed. Using default recipe.\n",
      "[NeMo W 2025-07-14 11:54:35 nemo_logging:405] The package `megatron.core` was not imported in this environment which is needed for SSMs.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections import llm\n",
    "\n",
    "pretrain = llm.qwen2_7b.pretrain_recipe(\n",
    "    name=\"qwen2_7b_pretraining\",\n",
    "    dir=f\"/path/to/checkpoints\",\n",
    "    num_nodes=2,\n",
    "    num_gpus_per_node=8,\n",
    ")\n",
    "\n",
    "pretrain = llm.qwen25_72b.pretrain_recipe(\n",
    "    name=\"qwen25_72b_pretraining\",\n",
    "    dir=f\"/path/to/checkpoints\",\n",
    "    num_nodes=8,\n",
    "    num_gpus_per_node=8,\n",
    ")\n",
    "\n",
    "# # To override the data argument\n",
    "# dataloader = a_function_that_configures_your_custom_dataset(\n",
    "#     global_batch_size=global_batch_size,\n",
    "#     micro_batch_size=micro_batch_size,\n",
    "#     seq_length=pretrain.model.config.seq_length,\n",
    "# )\n",
    "# pretrain.data = dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3f2454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment nemo.collections.llm.api.pretrain with id: nemo.collections.llm.api.pretrain_1752465313</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─── \u001b[0m\u001b[1;35mEntering Experiment nemo.collections.llm.api.pretrain with id: nemo.collections.llm.api.pretrain_1752465313\u001b[0m\u001b[92m ───\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /home/mzhyui/.nemo_run/experiments/nemo.collections.llm.api.pretrain/nemo.collections.llm.api.pretrain_1752465313/nemo.collections.llm.api.pretrain\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11:55:14] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job nemo.collections.llm.api.pretrain for experiment </span>                        <a href=\"file:///home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/nemo_run/run/experiment.py#744\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">744</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">nemo.collections.llm.api.pretrain</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11:55:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job nemo.collections.llm.api.pretrain for experiment \u001b[0m                        \u001b]8;id=470300;file:///home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=556995;file:///home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/nemo_run/run/experiment.py#744\u001b\\\u001b[2m744\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mnemo.collections.llm.api.pretrain\u001b[0m                                                      \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /home/mzhyui/.nemo_run/experiments/nemo.collections.llm.api.pretrain/nemo.collections.llm.api.pretrain_1752465313/nemo.collections.llm.api.pretrain\n",
      "Launched app: local_persistent://nemo_run/nemo.collections.llm.api.pretrain-sj9hbfkfwrtrl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment nemo.collections.llm.api.pretrain_1752465313 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment nemo.collections.llm.api.pretrain_1752465313 to finish\u001b[0m\u001b[92m ──────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.pretrain_1752465313</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mnemo.collections.llm.api.pretrain_1752465313\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.pretrain</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: nemo.collections.llm.api.pretrain-sj9hbfkfwrtrl\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /home/mzhyui/.nemo_run/experiments/nemo.collections.llm.api.pretrain/nemo.collections.llm.api.pretrain_1752465313/nemo.collections.llm.api.pretrain\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mnemo.collections.llm.api.pretrain\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: nemo.collections.llm.api.pretrain-sj9hbfkfwrtrl\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /home/mzhyui/.nemo_run/experiments/nemo.collections.llm.api.pretrain/nemo.collections.llm.api.pretrain_1752465313/nemo.collections.llm.api.pretrain\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job nemo.collections.llm.api.pretrain-sj9hbfkfwrtrl to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i.pretrain/0 WARNING: transformer_engine not installed. Using default recipe.\n",
      "i.pretrain/0 [NeMo W 2025-07-14 11:55:20 nemo_logging:405] The package `megatron.core` was not imported in this environment which is needed for SSMs.\n",
      "i.pretrain/0 [NeMo I 2025-07-14 11:55:20 nemo_logging:393] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "i.pretrain/0 [NeMo I 2025-07-14 11:55:20 nemo_logging:393] Downloading from https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json to /home/mzhyui/.cache/torch/megatron/megatron-gpt-345m_vocab\n",
      "i.pretrain/0 [NeMo I 2025-07-14 11:55:27 nemo_logging:393] Downloading from https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt to /home/mzhyui/.cache/torch/megatron/megatron-gpt-345m_merges\n",
      "i.pretrain/0 [NeMo I 2025-07-14 11:55:29 nemo_logging:393] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /home/mzhyui/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /home/mzhyui/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n",
      "i.pretrain/0 Traceback (most recent call last):\n",
      "i.pretrain/0   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "i.pretrain/0   File \"<frozen runpy>\", line 88, in _run_code\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/nemo_run/core/runners/fdl_runner.py\", line 72, in <module>\n",
      "i.pretrain/0     fdl_runner_app()\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/typer/main.py\", line 341, in __call__\n",
      "i.pretrain/0     raise e\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/typer/main.py\", line 324, in __call__\n",
      "i.pretrain/0     return get_command(self)(*args, **kwargs)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/click/core.py\", line 1442, in __call__\n",
      "i.pretrain/0     return self.main(*args, **kwargs)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/typer/core.py\", line 694, in main\n",
      "i.pretrain/0     return _main(\n",
      "i.pretrain/0            ^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/typer/core.py\", line 195, in _main\n",
      "i.pretrain/0     rv = self.invoke(ctx)\n",
      "i.pretrain/0          ^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/click/core.py\", line 1226, in invoke\n",
      "i.pretrain/0     return ctx.invoke(self.callback, **ctx.params)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/click/core.py\", line 794, in invoke\n",
      "i.pretrain/0     return callback(*args, **kwargs)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/typer/main.py\", line 699, in wrapper\n",
      "i.pretrain/0     return callback(**use_params)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/nemo_run/core/runners/fdl_runner.py\", line 67, in fdl_direct_run\n",
      "i.pretrain/0     fdl_fn = fdl.build(fdl_buildable)\n",
      "i.pretrain/0              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/building.py\", line 185, in build\n",
      "i.pretrain/0     result = daglish.MemoizedTraversal.run(_build, buildable)\n",
      "i.pretrain/0              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/daglish.py\", line 477, in run\n",
      "i.pretrain/0     return fn(root_obj, state)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/building.py\", line 176, in _build\n",
      "i.pretrain/0     sub_traversal = state.flattened_map_children(value)\n",
      "i.pretrain/0                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/daglish.py\", line 631, in flattened_map_children\n",
      "i.pretrain/0     return self._flattened_map_children(value, node_traverser)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/daglish.py\", line 580, in _flattened_map_children\n",
      "i.pretrain/0     self.call(subvalue, path_element)\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/daglish.py\", line 694, in call\n",
      "i.pretrain/0     return self.traversal.apply(value, new_state)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/daglish.py\", line 786, in apply\n",
      "i.pretrain/0     result = self.traversal_fn(value, state)\n",
      "i.pretrain/0              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/building.py\", line 180, in _build\n",
      "i.pretrain/0     return call_buildable(value, arguments, current_path=state.current_path)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/building.py\", line 119, in call_buildable\n",
      "i.pretrain/0     with reraised_exception.try_with_lazy_message(make_message):\n",
      "i.pretrain/0   File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "i.pretrain/0     self.gen.throw(value)\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/reraised_exception.py\", line 82, in try_with_lazy_message\n",
      "i.pretrain/0     raise decorate_exception(exc, message) from None\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/reraised_exception.py\", line 74, in try_with_lazy_message\n",
      "i.pretrain/0     yield\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/building.py\", line 120, in call_buildable\n",
      "i.pretrain/0     return buildable.__build__(*args, **kwargs)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/fiddle/_src/config.py\", line 783, in __build__\n",
      "i.pretrain/0     return self.__fn_or_cls__(*args, **kwargs)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/nemo/lightning/io/mixin.py\", line 590, in wrapped_init\n",
      "i.pretrain/0     original_init(self, *args, **kwargs)\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/argparse.py\", line 70, in insert_env_defaults\n",
      "i.pretrain/0     return fn(self, **kwargs)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py\", line 395, in __init__\n",
      "i.pretrain/0     self._accelerator_connector = _AcceleratorConnector(\n",
      "i.pretrain/0                                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py\", line 146, in __init__\n",
      "i.pretrain/0     self._set_parallel_devices_and_init_accelerator()\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py\", line 376, in _set_parallel_devices_and_init_accelerator\n",
      "i.pretrain/0     self._devices_flag = accelerator_cls.parse_devices(self._devices_flag)\n",
      "i.pretrain/0                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/lightning/pytorch/accelerators/cuda.py\", line 88, in parse_devices\n",
      "i.pretrain/0     return _parse_gpu_ids(devices, include_cuda=True)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/lightning/fabric/utilities/device_parser.py\", line 102, in _parse_gpu_ids\n",
      "i.pretrain/0     return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)\n",
      "i.pretrain/0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "i.pretrain/0   File \"/home/mzhyui/git/finai/.venv/lib/python3.12/site-packages/lightning/fabric/utilities/device_parser.py\", line 135, in _sanitize_gpu_ids\n",
      "i.pretrain/0     raise MisconfigurationException(\n",
      "i.pretrain/0 lightning.fabric.utilities.exceptions.MisconfigurationException: You requested gpu: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "i.pretrain/0  But your machine only has: [0]\n",
      "i.pretrain/0 \n",
      "i.pretrain/0 Fiddle context: failed to construct or call Trainer at <root>.trainer with positional arguments: (), keyword arguments: (accelerator='gpu', strategy=<nemo.lightning.pytorch.strategies.megatron_strategy.MegatronStrategy object at 0x748decad0200>, devices=8, num_nodes=8, callbacks=[<nemo.utils.exp_manager.TimingCallback object at 0x748decad00b0>], max_steps=300000, limit_val_batches=32, limit_test_batches=32, val_check_interval=500, log_every_n_steps=10, accumulate_grad_batches=1, use_distributed_sampler=False, plugins=<nemo.lightning.pytorch.plugins.mixed_precision.MegatronMixedPrecision object at 0x748decad01a0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job nemo.collections.llm.api.pretrain-sj9hbfkfwrtrl finished: FAILED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['nemo.collections.llm.api.pretrain']</span><span style=\"background-color: #272822\">                           </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.pretrain_1752465313\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.pretrain\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.pretrain\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">                </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['nemo.collections.llm.api.pretrain']\u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.pretrain_1752465313\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.pretrain\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.pretrain\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m                \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status nemo.collections.llm.api.pretrain_1752465313</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs nemo.collections.llm.api.pretrain_1752465313 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel nemo.collections.llm.api.pretrain_1752465313 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                              </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.pretrain_1752465313\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.pretrain_1752465313\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.pretrain_1752465313\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nemo_run as run\n",
    "\n",
    "run.run(pretrain, executor=run.LocalExecutor())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
